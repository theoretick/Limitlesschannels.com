---
layout: post
title: Appling Doing Project - Statistical and Rule-based Reflections in MT - Paper
date: 2011-11-30
category: writing
tags:
 - papers
 - writing
 - appliedlinguistics
 - linguistics
description: My final paper topic for Applied Linguistics on statistical and rule-based Machine Translation
---

30 November 2011  
LING435 - Applied Linguistics  

##Appling Doing Project: Statistical and Rule-Based Reflections in Machine Translation##

Lucas Charles  
Portland State University  

###Statistical and Rule-Based Reflections in Machine Translation###
For the topic of my doing project I pursued the unbelievably fascinating and far-reaching topic of Machine Translation.  This topic is one that has produced immense leaps in the last few decades yet has only become a "hot topic" in the last 10 years with the rise of (almost entirely) Google and the introduction of smartphones.  As our world has become more and more global and technological limitations no longer depend on hardware but merely the limits of ingenuity, there's been incredible jumps on all fronts of language.  Machine Translation (MT) has since moved from a field that could only be pursued by deep-pocketed militaries to corporations to individuals.  As researcher Don DePalma put it "In 1956, if you wanted MT, you had to go to the United States Navy or to the KGB to get it. Today, the options for using MT ranged from desktop to in-house server to free online access" (Common Sense Advisory 2011).  The past required computers that filled rooms where today such work can be done literally in the palm of the hand, as will be discussed later through DARPA's TRANSTAC project.  I chose this topic because it was one lightly addressed in class but it has become more relevant each day as a fixture of modern language usage.  Whether this is the domain of computer scientists or linguists (in this case Google and linguistic researchers) its sky-rocketing usage makes it an important cross-disciplinary language issue that has a complex and awesome (in the truest sense) future.  The choice then of which domain it falls into is irrelevant since the goal is to mediate social problems: here, communication.  To then use Applied Linguistics as Davies (2006) defines it, MT falls directly into the domain as a discipline drawing on a wide range of relevant fields (p. 4).  Linguistics is not the parent discipline but simply a parent discipline.  

In my daily life I have been recently seeing growing application for effective MT, ranging from travel to information perusal on the internet.  The appealing idea of a handheld Star-Trek-style translator to instantaneously convert one's language into another is quite desirable, and much closer than many may think.  In my life I have recognized several real world applications including autotranslation of many forms of media.  Speech to text is a closely related field of equal potential-- often simultaneous deployment-- and were it to be perfected one could stream any live television broadcast receiving on-the-fly subtitles throughout. With MT, those subtitles could display in any conceivable language.  One step further, the subtitles could be reprocessed by the machine through text to speech and the broadcast could be heard in any language, as well.  The seemingly limitless potential involved addresses communication so effectively as to change modern society completely.  One related project I have discussed with others was creating a podcast distribution startup, where the use of MT and minor editing could tap into markets for the podcasts well beyond their original language community.  A further development would be the eventual honing of these translation mappings of each language, be them through statistical or rule-based translation, to a small "DNA" for each.  With such pattern mappings the work of language theorists could be tested and confirmed in terms of language models within the mind.  Each piece of such DNA could easily prove Chomsky's UG theory or perhaps Saffran's Constrained Statistical Learning Framework (Fernandez, 2011, p. 101).  These are only a few of the possible applications of effective MT, so the question then becomes whether or not these are even attainable.  In my work for the "doing project" I pursued the question of exactly how far along the field is and how close people are to achieving such goals.  In my research I reviewed literature as well as discussed the prospects with an important researcher in the field.  I will first present background, then my research and interview with Dr. Oshika on the topic, and finally a reflection on the future relevance of MT.  
	
According to Decker (2010), who has worked in translation for decades, the idea of MT first developed around 1950 (p. 107) with overly optimistic projections on the modelling of language.  The idea then was that eventually computers would be fully capable of automatically and efficiently converting speech, yet as time has shown it is still not the case.  While much of today's translation is statistical machine-based, that's far from the only topic in the field (Decker, 2010, p. 108).  There is the older, labor-intensive "rule-based translation" in which programmers must define a ruleset that models syntactic behavior to use, but those who have done any work in syntax know what a juggernaut task this entails. As covered by Hall (2011), the goal of translation falls into two categories, reader-based translation and text-based translation (p. 235).  The difference is an important one as the focus falls to information retention or to receiver comprehension, or formal vs. functional, respectively (p. 236).  

Even as the groundwork for previous MT work was largely done by military intelligence, the world of MT today has been taken up by corporations.  While the target before was military necessity, the potential for instantaneous translation is key with the presence of the internet and information as currency.  Google as one of today's most invested proponents in information, having founded the company as a search engine and now with 48% of $58 billion in revenue coming from advertising, are applying more and more to information accessibility (Google 2011). In researching MT, Google increasingly came up and between my research and email exchanges with several friends at Google, I was able to gather a picture of both the investment and scope of their work in MT today.   Even at its founding, translation was a high priority, having made the site available in 26 languages within a year (Levy 2011).  In Levy's book on Google, In the Plex, he writes on the interesting and unromantic take the founders had on language: "\[Larry] Page and \[Sergey] Brin believed that artificial barriers such as language should not stand in the way of people's access to information" (p. 62).  Bearing such a perspective in mind, it's interesting how important Google's contribution has been today in the field of statistical MT.  The reason for Google's success and impact lies in their company focus: information.  Statistical MT relies on massive amounts of data and data has always been their focus.  Due to their unmatched massive corpus, internet spidering, and seemingly unlimited funds, today they have one of the most effective statistical translation systems available with 506 language pairs.  Even the page-ranking algorithms used by Google to rank accuracy and relevance were applied to millions of sites to distinguish the amateur and the "best" translations (Levy 2011, p. 64).  Thanks to Google's thoroughness in information accessibility and quality ranking, the principles of info theory were applied in an incredibly valuable way that has made Google one of the more effective statistical MTs today.  

Due to costs involved, some of the earliest work carried out in MT was in the 1970s by US military intelligence and DARPA.  DARPA, at the time renamed ARPA to tone down their "defense" emphasis for PR purposes, was one of the forerunners in funding and development for MT. DARPA contracted a number of companies to tackle the task including IBM, BBM, SRI, CMU (B. Oshika, personal communication, November 8, 2011).  To get an idea of the work involved in early MT, I was able to contact Beatrice Oshika, a linguistics researcher working for MITRE at the time. Dr. Oshika has been involved in MT with DARPA since its beginning and as recently as 2009 was involved in system assessment of translation devices developed for military deployment (Condon, et al. 2009).  I spoke with Dr. Oshika at length about her work, specifically on the Translation System for Tactical Use (TRANSTAC) handheld translator project.  TRANSTAC was DARPA's latest version of their work on translation, this time with software based on, coincidentally, Google's Android operating system and hardware.  The project involved three steps: (1) speech to text, (2) machine translation, (3) text to speech.  Once completed, the goal of TRANSTAC was to be deployed in the middle east for US military in situations where a human translator wasn't present, i.e. checkpoints and random seizures.  While the speech-to-text and text-to-speech components are fascinating in and of themselves, the nexus of our discussion fell on the difficulties and experiences of real-world tactical deployment of MT.  The hundreds of hours of initial data for the project were collected between interactions with military personnel and Iraqi civilians, yet it was incredibly specific situational interactions and thus limited in a key capacity, unlike Google's widespread data environments.  TRANSTAC also utilized a statistical system with this data and curation by human translators (B. Oshika, personal communication, November 8, 2011).  Names were never handled well.  An important element to TRANSTAC was the way that collected data was reflected.  When I inquired about polite versus correct transcription, Oshika pointed out that roadside encounters are not standard Arabic, but colloquial.  For one, they had to edit out prolific use of swear words, for social acceptability.  This is both the strength and weakness for the statistical approach, it reflects accurate usage, be it acceptable or not. We'll return to this divergence later. Similarly in training, TRANSTAC worked just like any human child, with success confirming, failure discouraging.  Such practice was clunky but the systems did actual constitute behavioral learning computers.  

In all of my work studying the implementation of MT I received several interesting revelations regarding both the continuing limitations and potential of the technique.  Of course their are some key limitations that have yet to be solved and seem unlikely to be in the near future such as poetic verse, name difficulty, Grice's relevance (or politeness), prosody features including intonation, and the issue and namesake of Decker's (2010) essay "The Challenge of Ambiguity." As of yet, these issues haven't been solved but they are hardly restricted to the domain of MT.  Every issue listed has been a problem in translation in general but are likewise issues for any non-native speaker.  Issues in such speech arise in nearly all language fields, often as speech errors.  As Hall et al. (2011) address them, these divergences arise in discursive psychology (p. 87), language variation (p. 45), and even the conception of "standard language."  As cited in Hall et al.'s work, Preston's idea of a "folk theory of language" with its linguistically incorrect but perceived monolithic structure places dialect and speech errors side-by-side as daughters of "ordinary language" (p. 32).  As Oshika said, names proved difficult for TRANSTAC, something that holds true for any language learner, as well. MT is merely a child in perpetual acquisition.  

In terms of translation theory, I'm in agreement with a quote in Hall et al. from one of the greatest writers ever, Vladimir Nabokov. Hall et al. (2011) attribute Nabokov with the quote "\[t]he clumsiest literal translation is a thousand times more useful than the prettiest paraphrase" (p. 237). An interesting aspect of statistical MT is the way that it circumvents the issue almost entirely by leaving the core philosophy to the masses, operating by "majority rules." To reach the truest translation I tend to think a union between statistical and rule-based approaches would be best. Language works in opposition of two paradigms, our reality of language and our psychology of language. Bearing in mind the reality of common usage (statistical) we must similarly consider the set of rules speakers maintain whether or not they manifest (rule-based).  Considering the frequency of speech errors which some say manifest as high as in 20-30% of speech, the target utterances are often missed (Santelmann 2011).  To compare the limitations in MT with the issues involved in language as a whole, MT is well on its way to a finished product, yet the issue now rests in problems of proper application not ones of implementation.  

###References###

Common Sense Advisory (2011). As content volume explodes, machine translation becomes an inevitable part of global content strategy \[Press release]. Retrieved from http://www.pr.com/press-release/371195  
Condon, S., Arehart, M., Doran, C., Parvaz, D., Aberdeen, J., Megerdoomian, K., Oshika, B., Sanders, G. (2009). Automated metrics for speech translation. Retrieved from http://www.mitre.org/work/tech_papers/tech_papers_09/09_3822/  
Decker, N. (2010). Machine translation: the challenge of ambiguity. In S. Behren & J. Parker (Eds.), Language in the real world (pp. 107-122). New York: Routledge.  
Davies, A. (2004). The handbook of applied linguistics. Malden: Blackwell.  
Fernandez, E. & Cairns, H. (2011). Fundamentals of psycholinguistics. West Sussex: Wiley-Blackwell.  
Google. (2011). 2011 Financial Tables. Available from http://investor.google.com/financial/tables.html  
Klatt, D. H. (1977). Review of the ARPA speech understanding project. Acoustic Society of America, J(62), 1345-1366. doi: 10.1121/1.381666  
Levy, Steven (2011). In the Plex. New York: Simon & Schuster.  
Santelmann, L. (2011). Current Themes and Debates \[PowerPoint slides]. Retrieved from http://d2l.pdx.edu.  
